\section{Analyzing group sequential trials\label{sec:Analysis}}
We present several ways to review and interpret interim and final results from group sequential trials. 
Generally, regulatory agencies will have interest in well-controlled Type I error and unbiased treatment estimates.
\subsection{The CAPTURE data}
We consider interim \cite{EAST} and final \cite{CAPTURE} data from the CAPTURE trial.
The interim data presented here is from finalized datasets rather than the actual data that was analyzed at the time of interim analyses.
Also, we take a binomial analysis approach here using the method of Miettinen and Nurminen \cite{MandN}; the original study analyses used the logrank test. 
The CAPTURE study was orginally designed using symmetric bounds, and the final planned sample size was 1400 patients.
The trial was stopped after analyzing the data from 1050 patients.
Enrollment continued during follow-up, data entry and cleaning, adjudication and analysis of the data.
By the time of the 1050 patient analysis was evaluated and the decision was made to stop the trial, a total of 1265 patients had been enrolled.
\bigskip 
\begin{table}
\begin{center}
\caption{The CAPTURE data\label{CAPTUREdata}}
\begin{tabular}
[c]{cccccccc}\hline
   &\multicolumn{3}{c}{Placebo}&\multicolumn{3}{c}{Experimental}\\
Analysis    &Events&n&\% &Events &n&\% &Z \\ \hline
1   &30	&175	&17.1\%	&14	&175	&8.0\% &2.58 \\
2   &55	&353	&15.6\%	&37	&347	&10.7\%&1.93\\
3   &84	&532	&15.8\%	&55	&518	&10.6\%&2.47 \\
4   &101	&635	&15.9\%	&71	&630	&11.3\%&2.41 \\ \hline
\end{tabular}
\end{center}
\end{table}
\bigskip

The Z-statistics in Table \ref{CAPTUREdata} can be computed with the \code{testBinomial} function as follows.

\begin{verbatim}
n1 <- c(175, 353, 532, 635)
n2 <- c(175, 347, 518, 630)
x1 <- c( 30,  55,  84, 101)
x2 <- c( 14,  37,  55,  71)
z <- testBinomial(x1=x1, x2=x2, n1=n1, n2=n2)

\end{verbatim}

\subsection{Testing significance of the CAPTURE data}
The Z-statistics computed above can only be interpreted in context of the study design.
The original design used a custom spending function which will has not been published and will not be discussed further here.
We will use the default spending functions for \code{gsDesign()} along with using 80\% power and starting with a fixed design sample size obtained using the Farrington and Manning \cite{FarringtonManning} method.
Largely because of the futility bound used for the default design, the sample size for this design is 1491 as opposed to the 1400 planned for CAPTURE.

\begin{verbatim}
n.fix <- nBinomial(p1=.15, p2=.1, beta=.2)
x <- gsDesign(k=4, n.fix=n.fix, beta=.2)
x$n.I
\end{verbatim}

To reset the interim analyses to those actually performed in the CAPTURE trial, we re-run \code{gsDesign()}, resetting the timing of analyses and adding the 1265 patient analysis as an additional interim analysis.
\begin{verbatim}
xmod <- gsDesign(k=5, n.fix=n.fix, beta=.2, 
                 n.I=c(ntot, x$n.I[4]), maxn.IPlan=x$n.I[4])
\end{verbatim}
The resulting upper bounds are 3.18, 2.87, 2.52, 2.31, and 2.04.
Thus, if analyses had been performed as above for the default design it would have demonstrated statistical significance at the n=1265 analysis had a Z-statistic of 2.41 which is greater than the boundary of 2.31 for that analysis.
Note that this is a numerical example only, as the analysis at $n$=1265 was performed because of the interim treatment effect at $n$=1050.
The distribution theory for group sequential design requires that timing of interims is independent of interim test statistics.
We will provide a technical resolution of this problem in a discussion of sample size adaptation.

\subsection{Stage-wise p-values}
Fairbanks and Madsen \cite{FairbanksMadsen} provide a method for computing p-values for a symmetric group sequential trial design once a boundary has been crossed.
Here we will consider just p-values for positive efficacy findings for asymmetric designs.
We assume for some $i$ in $1,2,\ldots,k$ that an upper bound is first crossed at analysis $i$ with a test statistic values $z_i$.
The stage-wise p-value uses the same computational method as $\alpha^+(0)$ from (\ref{alpha+(theta)}).
\begin{equation}
p_{SW}=P_{0}\{\{Z_{i}\geq z_{i}\}\cap_{j=1}^{i-1}%
\{Z_{j}<b_{j}\}\}\label{eq:pSW}%
\end{equation}
This formula can still be used for the final analysis when the upper bound is never crossed.
This method of computing p-values emphasizes early positive results and de-emphasizes late results.
No matter how positive a result is after the first analysis, the p-value associated with a positive result will not be smaller than a first analysis result that barely crosses its bound.
There is no way to compute a p-value if, for some reason, you stop a trial early without crossing a bound. 
For the CAPTURE data analyzed according to the default design derived above, we compute a stagewise p-value of 0.11 as follows

\begin{verbatim}
> y <- gsProbability(k=4, theta=0, n.I=ntot, a=array(-20,4), 
+                   b=c(xmod$upper$bound[1:3], z[4]))
> y$upper$prob
             [,1]
[1,] 0.0007264271
[2,] 0.0018577690
[3,] 0.0047510699
[4,] 0.0041621310
> sum(y$upper$prob)
[1] 0.01149740
\end{verbatim}

\subsection{Repeated confidence intervals and p-values}
Repeated confidence intervals use the nominal Type I error at each interim analysis to compute confidence bounds in the usual fashion.
For the binomial analysis of the CAPTURE trial we use Miettinen and Nurminen \cite{MandN} confidence intervals.
\begin{verbatim}
y <- NULL
for(i in 1:4) 
{    y <- c(y, ciBinomial(x1=x1[i], x2=x2[i], n1=n1[i], n2=n2[i], 
           alpha=2 * pnorm(-xmod$upper$bound[i])))
}
\end{verbatim}

